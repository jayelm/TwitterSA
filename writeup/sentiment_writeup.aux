\relax 
\citation{pang02}
\citation{turney02}
\citation{pak10}
\@writefile{toc}{\contentsline {section}{\numberline {1}Background}{1}}
\citation{go09}
\citation{go09}
\citation{gamallo14}
\citation{narayanan13}
\citation{pak10}
\@writefile{toc}{\contentsline {section}{\numberline {2}Problem Formulation}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Corpus}{2}}
\citation{huang03}
\citation{narayanan13}
\citation{pak10}
\citation{rennie01}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Naive Bayes}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Technologies}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Classifier Evaluation}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Preprocessing and Feature Vectorization}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}Preprocessing}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.2}The Bag-Of-Words Model}{5}}
\newlabel{ssub:the_bag_of_words_model}{{4.1.2}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.3}Laplace Smoothing}{6}}
\newlabel{ssub:laplace_smoothing}{{4.1.3}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Initial Evaluation: Bernoulli versus Multinomial Naive Bayes}{6}}
\newlabel{sub:initial_evaluation}{{4.2}{6}}
\citation{manning08}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Bernoulli vs Multinomial NB plotted against data set size}}{7}}
\newlabel{fig:bow_bernoulli_vs_multinomial}{{1}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Improving Classification Accuracy}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}N-grams}{7}}
\newlabel{ssub:n_grams}{{4.3.1}{7}}
\citation{manning08}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Classifier accuracy for the cumulative addition of N-grams, 25000 data set, averaged over 5 samples}}{8}}
\newlabel{tab:ngrams}{{1}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Reducing features: select $k$-best}{8}}
\newlabel{ssub:reducing_features_select_k_best}{{4.3.2}{8}}
\citation{manning08}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Select $k$-best feature selection performance on 25000 data set (bigrams + unigrams), averaged over 5 splits}}{9}}
\newlabel{fig:k_best}{{2}{9}}
\citation{davis13}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.3}Other Feature Selection Techniques}{10}}
\newlabel{ssub:variance_threshold_feature_removal}{{4.3.3}{10}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.4}More Data - Diminishing Returns}{10}}
\newlabel{ssub:more_data}{{4.3.4}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Building the Web App}{10}}
\newlabel{sec:web}{{5}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Backend}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Effect of large training sets on classifier accuracy}}{11}}
\newlabel{fig:large_data_sets}{{3}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Frontend}{11}}
\citation{wilson05}
\citation{pang02}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Example Web Application Screenshot for Twitter User @BarackObama}}{12}}
\newlabel{fig:obama}{{4}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{12}}
\citation{gamallo14}
\citation{narayanan13}
\citation{gamallo14}
\@writefile{toc}{\contentsline {paragraph}{Ideas for Further Work}{13}}
\bibcite{davis13}{1}
\bibcite{gamallo14}{2}
\@writefile{toc}{\contentsline {section}{\numberline {A}Appendix: Python script help output}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}\texttt  {classifiers.py}}{14}}
\newlabel{sub:classifiers}{{A.1}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}\texttt  {TwitterSA.py}}{14}}
\newlabel{sub:twittersa}{{A.2}{14}}
\bibcite{go09}{3}
\bibcite{huang03}{4}
\bibcite{manning08}{5}
\bibcite{narayanan13}{6}
\bibcite{pak10}{7}
\bibcite{pang02}{8}
\bibcite{rennie01}{9}
\bibcite{turney02}{10}
\bibcite{wilson05}{11}
